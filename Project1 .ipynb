{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group: EASY5Aplus\n",
    "## Group member: Ruiting Zhu, Zhedi Zhang, Heng'an Wang, Yuxin Liang, Tao Zhang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhurt\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3.png](https://s2.loli.net/2024/09/28/hcrXkvLSYuBVbMU.png)\n",
    "![4.png](https://s2.loli.net/2024/09/28/HspaGuhRZr1qzK6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: N=100000, T=10, alpha=0.001, pi=0.5\n",
      "Optimal Schedule:\n",
      "[10100.  9900.  9840.  9888.  9976. 10001. 10048. 10067. 10087. 10093.]\n",
      "Total shares traded:\n",
      "90067\n",
      "Traded percentage of target:\n",
      "0.90067\n",
      "Total time DP runs 1094.8082859516144\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def DP(N: int, T: int, alpha: float, pi: float)-> np.ndarray:\n",
    "    '''\n",
    "    Use dynamic programming to calculate maximum traded shares at each time period.\n",
    "    \n",
    "    N: Total shares\n",
    "    T: Time periods for trading\n",
    "    alpha: parameter in calculating actual traded shares\n",
    "    pi: parameter in calculating actual traded shares\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # initialize variables\n",
    "    total = np.zeros((T, N + 1))  # initialize total shares traded as a zero matrix\n",
    "    S = np.zeros((T, N + 1))  # initialize optimal shares plan to trade (not actually traded) as a zero matrix\n",
    "    M = np.zeros((T, N + 1))  # initialize M as a zero matrix\n",
    "\n",
    "    iarray = np.arange(N + 1)  \n",
    "    revi = N - iarray  # remaining stock of shares\n",
    "    candidates = np.zeros(N + 1)  # candidates of the answer\n",
    "\n",
    "    # initialize the trade at t=0\n",
    "    M[0, :] = np.ceil(0.9 * iarray)  # calculate the value of M \n",
    "    S[0, :] = iarray  # initial share traded\n",
    "    total[0, :] = np.ceil((1 - alpha * M[0, :]**pi) * iarray)  # calculate the total revenue traded at time 0\n",
    "\n",
    "    \n",
    "    # backward induction\n",
    "    for t in range(1, T):\n",
    "        for n in range(0, N + 1):\n",
    "            # calculate the traded shares of different candidates\n",
    "            candidates[:n + 1] = total[t - 1, revi[N - n:]] + np.ceil((1 - alpha * np.ceil(0.1 * M[t - 1, revi[N - n:]] + 0.9 * iarray[:n + 1])**pi) * iarray[:n + 1])\n",
    "            best = np.argmax(candidates[:n + 1])  # find the optimal plan-to-trade amount\n",
    "            total[t, n] = candidates[:n + 1][best]  # record the optimal actual-traded amount\n",
    "            S[t, n] = best  # record the optimal plan-to-trade amount\n",
    "            M[t, n] = np.ceil(0.1 * M[t - 1, int(n - S[t, n])] + 0.9 * S[t, n])  # update M each period using S\n",
    "\n",
    "    \n",
    "    # extract optimal trading schedule\n",
    "    schedule = np.zeros(T)  # build a optimal trading schedule matrix\n",
    "    remaining_shares = N  \n",
    "\n",
    "    # backward induction\n",
    "    for t in range(T - 1, -1, -1):\n",
    "        schedule[t] = S[t, int(remaining_shares)]  # extract the optimal plan-to-trade amount at t\n",
    "        remaining_shares -= schedule[t]  # update the remaining shares\n",
    "\n",
    "    traded = total[T - 1, N]  # total amount traderd\n",
    "\n",
    "    return schedule, traded\n",
    "\n",
    "\n",
    "# get result\n",
    "N, T, alpha, pi = 100000, 10, 0.001, 0.5\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "schedule, traded = DP(N, T, alpha, pi)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"Parameters: N={N}, T={T}, alpha={alpha}, pi={pi}\")\n",
    "print(\"Optimal Schedule:\")\n",
    "print(schedule)\n",
    "print(\"Total shares traded:\")\n",
    "print(int(traded))\n",
    "print(\"Traded percentage of target:\")\n",
    "print(traded / N)\n",
    "print('Total time DP runs', t1 - t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Use the original file, do basic data cleaning\n",
    "    '''\n",
    "    \n",
    "    # filter needed data\n",
    "    df = df.iloc[:, : 8]\n",
    "    column_name = df.loc[2].tolist()\n",
    "    df = df.loc[3:]\n",
    "    df.columns = column_name\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # data type conversion\n",
    "    df.loc[:, 'Dates'] = pd.to_datetime(df['Dates'], format='%m/%d/%y %H:%M')\n",
    "    df.set_index('Dates', inplace=True)\n",
    "\n",
    "    columns_to_types = {\n",
    "    \"Open\": \"float\",\n",
    "    \"Close\": \"float\",\n",
    "    \"High\": \"float\",\n",
    "    \"Low\": \"float\",\n",
    "    \"Value\": \"float\",\n",
    "    \"Volume\": \"int\",\n",
    "    \"Number Ticks\": \"int\"}\n",
    "\n",
    "    for column, type_ in columns_to_types.items():\n",
    "        df[column] = df[column].astype(type_)\n",
    "    \n",
    "    return df\n",
    "\n",
    "        \n",
    "def Volume_data(df: pd.DataFrame) -> list:\n",
    "    '''\n",
    "    Use the 'Volume' data of Tesla, divide into intervals, present as list and sublist\n",
    "    '''\n",
    "    # make sure index is datetime\n",
    "    df.index = pd.to_datetime(df.index, format='%m/%d/%y %H:%M')\n",
    "\n",
    "    # (1) Extract the first half of Tesla data, the data should include a whole day range\n",
    "    # Count total days\n",
    "    daily_counts = df.groupby(df.index.date).size()\n",
    "    cumulative_counts = daily_counts.cumsum()\n",
    "    \n",
    "    # Find the last complete date in the first half of data\n",
    "    half_index = len(df) // 2\n",
    "    last_complete_date = cumulative_counts[cumulative_counts <= half_index].index[-1]\n",
    "\n",
    "    last_complete_date = pd.Timestamp(last_complete_date)\n",
    "    first_half_df = df[df.index.normalize() <= last_complete_date]\n",
    "\n",
    "    # (2) Extract data from 9:30 to 11:30\n",
    "    filtered_df = first_half_df.between_time('9:30', '11:29')\n",
    "\n",
    "    # (3) Devide data into intervals, with each interval containing 10 volume data\n",
    "    result = []\n",
    "    for date, daily_data in filtered_df.groupby(filtered_df.index.date):\n",
    "        start_time = datetime.combine(date, datetime.strptime('09:30', '%H:%M').time())\n",
    "        grouped = []\n",
    "        for i in range(12):  # there are 12 intervals for each day from 9:30 to 11:30\n",
    "            start = start_time + timedelta(minutes=10 * i)\n",
    "            end = start + timedelta(minutes=10)\n",
    "            group = daily_data[(daily_data.index >= start) & (daily_data.index < end)]['Volume'].tolist()\n",
    "            grouped.append(group)\n",
    "        \n",
    "        grouped = [group for group in grouped if group]\n",
    "        result.extend(grouped)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def get_score(ori_data: pd.DataFrame, optimal: list) -> float:\n",
    "    '''\n",
    "    Compare Tesla Volume with schedule we get in Q1, get final score\n",
    "    ''' \n",
    "    # Tesla Volume data\n",
    "    precessed_data = data_preprocess(ori_data)\n",
    "    Tesla_volume = Volume_data(precessed_data)\n",
    "    \n",
    "    # optimal schedule of Q1\n",
    "    #optimal_schedule = [int(x) for x in optimal]\n",
    "    \n",
    "    # interval_score\n",
    "    interval_scores = []\n",
    "    for interval in Tesla_volume:\n",
    "        interval_score = sum(min(x, (y / 100)) for x,y in zip(optimal, interval))\n",
    "        interval_scores.append(interval_score)\n",
    "\n",
    "    # final_score\n",
    "    final_score = sum(interval_scores) / len(interval_scores)\n",
    "\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-828282e05be0>:2: DtypeWarning: Columns (0,1,2,3,4,5,6,7,10,11,12,13,14,15,16,19,20,21,22,23,24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  Tesla_ori_data = pd.read_csv(\"TSLA.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8113.97704545455"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get result\n",
    "Tesla_ori_data = pd.read_csv(\"TSLA.csv\")\n",
    "optimal = [10100, 9900, 9840, 9888, 9976, 10001, 10048, 10067, 10087, 10093]\n",
    "get_score(Tesla_ori_data, schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes quite a long time and didn't finished before the ddl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_pi(start: float, end: float, step: float) -> np.ndarray:\n",
    "    '''\n",
    "    Find the optimal pi given N, T and alpha to maximize the score.\n",
    "    This function allow self-defined step of pi.\n",
    "    '''\n",
    "    # create an array containing all pi values\n",
    "    pi_values = np.arange(start, end + step, step)\n",
    "\n",
    "    # Calculate score for each pi\n",
    "    scores = np.array([get_score(Tesla_ori_data, DP(N, T, alpha, pi)[0]) for pi in pi_values])\n",
    "\n",
    "    # find index, and optimal pi\n",
    "    best_index = np.argmax(scores)\n",
    "    best_pi_value = pi_values[best_index]\n",
    "    max_score = scores[best_index]\n",
    "\n",
    "    return best_pi_value, max_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given N = 100000, T = 10, alpha = 0.001\n",
      "When step = 0.1, best pi =0.4, maximum score =8114.817954545459 \n"
     ]
    }
   ],
   "source": [
    "N, T, alpha = 100000, 10, 0.001\n",
    "start, end = 0.3, 0.7\n",
    "\n",
    "print('Given N = 100000, T = 10, alpha = 0.001')\n",
    "for i in [0.1, 0.01, 0.001]:\n",
    "    optimal_pi, max_score = best_pi(start, end, i)\n",
    "    print(f'When step = {i}, best pi ={optimal_pi}, maximum score ={max_score} ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes relatively shorter time but didn't get enough time to finished before the ddl. Here we use N=10000 to see the effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: pi = 0.3, grad = -81033510.10101661, loss = -6278553.724747476\n",
      "Iteration 2: pi = 0.7, grad = -2187613.6363632977, loss = -6367240.631313137\n",
      "Convergence achieved.\n",
      "Optimal pi: 0.7\n",
      "Maximum score: 6367.240631313137\n"
     ]
    }
   ],
   "source": [
    "# define loss function\n",
    "def loss_function(pi, Tesla_ori_data, N, T, alpha) -> float:\n",
    "    '''\n",
    "    define the loss function according to the score\n",
    "    '''\n",
    "    optimal, traded = DP(N, T, alpha, pi)\n",
    "    score = get_score(Tesla_ori_data, optimal)\n",
    "    return -score*1000\n",
    "\n",
    "\n",
    "# define gradient\n",
    "def numerical_gradient(pi, Tesla_ori_data, N, T, alpha, epsilon=1e-3) -> float:\n",
    "    '''\n",
    "    calculate gradient using finite difference method\n",
    "    '''\n",
    "    loss_plus_epsilon = loss_function(pi + epsilon, Tesla_ori_data, N, T, alpha)\n",
    "    loss_at_pi = loss_function(pi, Tesla_ori_data, N, T, alpha)\n",
    "    grad = (loss_plus_epsilon - loss_at_pi) / epsilon\n",
    "    return grad\n",
    "\n",
    "\n",
    "# find the optimal pi between 0.3 and 0.7\n",
    "def gradient_descent_pi(Tesla_ori_data, N, T, alpha, start_pi=0.3, learning_rate=0.001, tolerance=1e-6, max_iterations=1000) -> float:\n",
    "    '''\n",
    "    find the optimal pi that can reach the bottom of the gradient\n",
    "    self-define start_pi, learning_rate, tolerance according to the learning outcome\n",
    "    '''\n",
    "    pi = start_pi  # initialize pi\n",
    "    for iteration in range(max_iterations):\n",
    "        grad = numerical_gradient(pi, Tesla_ori_data, N, T, alpha)  # calculate gradient\n",
    "        new_pi = pi - learning_rate * grad  \n",
    "\n",
    "        # ensure the range of pi\n",
    "        new_pi = np.clip(new_pi, 0.3, 0.7)\n",
    "\n",
    "        # print iteration\n",
    "        print(f\"Iteration {iteration + 1}: pi = {pi}, grad = {grad}, loss = {loss_function(pi, Tesla_ori_data, N, T, alpha)}\")\n",
    "\n",
    "        # check tolerance\n",
    "        if abs(new_pi - pi) < tolerance:\n",
    "            print(\"Convergence achieved.\")\n",
    "            break\n",
    "\n",
    "        pi = new_pi  \n",
    "\n",
    "    # optimal pi\n",
    "    return pi\n",
    "\n",
    "\n",
    "N = 10000\n",
    "T = 10\n",
    "alpha = 0.001\n",
    "\n",
    "best_pi = gradient_descent_pi(Tesla_ori_data, N, T, alpha)\n",
    "print(f\"Optimal pi: {best_pi}\")\n",
    "print(f\"Maximum score: {-loss_function(best_pi, Tesla_ori_data, N, T, alpha)/1000}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Contribution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ruiting Zhu: \n",
    "  * Responsible for solving all questions, while adding explanations and code comments for all. \n",
    "  * Deduct the mathematical model of the question 1, figure out the logic, resolve member's questions and discuss with the group, jointly write and refine the code. \n",
    "  * Completed most of the work of question 2 including code writing and briefness checking. \n",
    "  * Solved question 3 independently using two approaches with briefness checking and runtime optimization. \n",
    "  * Organized and participated in all group discussions, discussed the problem-solving approach, and joined the TA's office hours with teammates.\n",
    "* Zhedi Zhang: \n",
    "  * Write and improve the code of question 1. Deduct the mathematic model with teammates. Write the final version of the code. \n",
    "  * Discussion: join all the discussion parts and go to the ta’s office hour asking questions.\n",
    "* Heng'an Wang: \n",
    "  * Participate in all zoom meeting group discussion and provide the draft code version of task1 and the run result of optimal schedule for other team members' reference.\n",
    "  * Discuss the logic of dynamic programming with other team members and apply the DP1-baseline approach model from lecture slide to task1 to figure out the Vectorization and forloop part of the code.\n",
    "  * Debug task1 and task3 code in v1 to test and optimize the run time.\n",
    "  * Join with other team members in TA's office hour to ask questions and discuss how to correct forloop and update M in different T.\n",
    "* Kexin Liang: \n",
    "  * Write and Improve Code. Provide data cleaning code for question 2 and improve the calculation speed for the third question.\n",
    "  * Cooperation and discussion. Specifically discussed the project’s tasks logic with others，the project’s method used and shared own code with others. Attend in person discussion.\n",
    "* Tao Zhang: **(highly-conflicted contribution, need further discussion with professor or TA)**\n",
    "  * Discussion and determination of the code approach for Task 1 & Task 2; Writing the code for Task 1 (non-adopted version)；Functional testing and validation of Task 3 in version 1; Functional testing and validation of Task 1, 2, & 3 in version 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
